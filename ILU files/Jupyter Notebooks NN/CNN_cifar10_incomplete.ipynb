{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_cifar10_incomplete.ipynb","provenance":[{"file_id":"17G7NlmTTB21ibh5VQt5CZVFy3lQ_NKZb","timestamp":1571116698460},{"file_id":"https://github.com/HenningBuhl/DLKTF/blob/master/DigitalXchange_MNIST_MLP.ipynb","timestamp":1564238868836}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tcs2oe8wmRlH"},"source":["# CNN mit Keras für CIFAR-10  "]},{"cell_type":"markdown","metadata":{"id":"PV6vEpTnmUHA"},"source":["## Problemstellung - 10 Objektklassen"]},{"cell_type":"markdown","metadata":{"id":"0s7MvT42tP2a"},"source":["Die Aufgabe, Objektklassen anhand eines kleinen Farbbildes zu erkennen, ist ein sehr komplexes Problem für einen Computer. Für ein solches Problem sind CNN gut geeignet."]},{"cell_type":"markdown","metadata":{"id":"aEpaoGnOtQ1O"},"source":["## Notwendige Libraries + Setup GPU"]},{"cell_type":"markdown","metadata":{"id":"GMSXLWy3nErl"},"source":["Die Berechnungen dieses Dokuments sind rechenaufwändiger. Daher bietet es sich an eine Funktion von Google Colab zu nutzen. Eine GPU kann über\n","\n","*   Edit -> Notebook Settings -> Hardware acceleration -> GPU\n","\n","ausgewählt werden (ist aber auch der Default)."]},{"cell_type":"code","metadata":{"id":"BBqxPfXxLzsq"},"source":["import numpy as np\n","import keras as keras\n","from keras.datasets import cifar10\n","#%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jc4hsVGeuvLS"},"source":["## CIFAR Data Set & Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"Ui5klECPuvr2"},"source":["Wir laden die Daten und plotten von jeder Klasse das erste Bild als Beispiel \n"]},{"cell_type":"code","metadata":{"id":"q4kh3zwlmSKu"},"source":["(xTrain, yTrain), (xTest, yTest) = cifar10.load_data() \n","noOfClasses = 10\n","im = []\n","import matplotlib.pyplot as plt\n","fig = plt.figure()\n","for i in range(noOfClasses):\n","    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n","    first = np.flatnonzero(yTrain == i)[0] \n","    im.append(xTrain[first,:,:,:])\n","    ax.set_title(i)\n","    ax.imshow(im[i])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cZ8pv_6RGYwb"},"source":["## Normalisieren und Formatieren der Daten"]},{"cell_type":"markdown","metadata":{"id":"crVm6TSp70-u"},"source":["Nun normieren wir jedes Input-Bild auf [0,1].\n","\n","Schließlich transformieren wir den Output (jeweils eine Ziffer 0-9) in ein **\"one-hot-encoding\"**, also einen binären Vektor der Dimension 10 mit einer 1 bei der richtigen Ziffer."]},{"cell_type":"code","metadata":{"id":"xwOy8mLLGZMN"},"source":["from keras.utils import np_utils\n","YTrain = np_utils.to_categorical(yTrain, noOfClasses)\n","YTest  = np_utils.to_categorical(yTest, noOfClasses)\n","XTrain = xTrain/255.0\n","XTest  = xTest/255.0\n","\n","XTrain.shape\n","YTrain[0,:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iP5M9mZMGZZ9"},"source":["## Trainieren des CNN mit Keras"]},{"cell_type":"code","metadata":{"id":"8S6e0Na4K_1C"},"source":["# Die Lernrate beeinflusst wie stark die Werte bei einem Parameterupdate\n","# verändert werden. Zu große Lernraten führen zu Oszillationen und\n","# zu kleine Lernraten sorgen für ein zu langsames Lernen.\n","learning_rate = 0.001\n","\n","# Die batch_size ist die Anzahl der Trainingsbeispiele, für die die Deltas akkumuliert\n","# werden, bevor ein Parameter-Uupdate durchgeführt wird.\n","batch_size = 64 # 32 #128\n","\n","# Die Anzahl der Epochen bestimmt wie oft die gesamten Daten gelernt werden\n","# sollen. Bei zu wenig Epochen hat das Netz noch nicht konvergiert. Bei\n","# zu vielen Epochen wird das Netzwerk stagnieren und im schlimmsten Fall\n","# die Trainingsdaten auswendig lernen.\n","epochs = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X8DNK4M7kgyd"},"source":["Aufbau des CNN"]},{"cell_type":"code","metadata":{"id":"yADz0-XcRvmc"},"source":["from keras.models import Sequential\n","from keras import layers\n","from keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","\n","l2Reg = 0.001 #0.001\n","\n","CNN = Sequential()\n","CNN.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',kernel_regularizer=l2(l2Reg),\n","                      input_shape=(32,32,3)))\n","CNN.add(layers.MaxPool2D(pool_size=(2, 2),padding='same'))\n","CNN.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',kernel_regularizer=l2(l2Reg)))\n","CNN.add(layers.MaxPool2D(pool_size=(2, 2),padding='same'))\n","CNN.add(layers.Conv2D(64,(3,3),padding='same',activation='relu',kernel_regularizer=l2(l2Reg)))\n","CNN.add(layers.MaxPool2D(pool_size=(2, 2),padding='same'))\n","CNN.add(layers.Conv2D(64,(3,3),padding='same',activation='relu',kernel_regularizer=l2(l2Reg)))\n","CNN.add(layers.MaxPool2D(pool_size=(2, 2),padding='same'))\n","CNN.add(layers.Flatten())\n","### Aufgabe\n","### ??? CNN.add(????)\n","### ??? CNN.add(????)\n","CNN.summary()\n","CNN.compile(optimizer=Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfB9Ut7Asep0"},"source":["$\\color{red}{\\mbox{Programmieraufgabe}}$: Vervollständigen Sie das Netz hinter `layers.Flatten()`: Ergänzen Sie einen Hidden Layer mit 512 Neuronen und ReLU-Aktivierung, gefolgt von einem Hidden Layer mit 256 Neuronen mit ReLU-Aktivierung und schließlich einen Output-Layer (welche Größe?) mit einer zum Output passenden Aktivierung (welcher?)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IK0wUDpwkaSO"},"source":["Trainieren des CNN:"]},{"cell_type":"code","metadata":{"id":"2bIxBO7bkXOQ"},"source":["CNN.fit(XTrain,YTrain,epochs=epochs,batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KzZLabNY-HmX"},"source":["Evaluieren des CNN auf dem Test-Set:"]},{"cell_type":"code","metadata":{"id":"AzYBpBxZRHUj"},"source":["yPred = CNN.predict(XTest)\n","choice = np.argmax(yPred, axis=1)\n","\n","confusionMatrix = np.zeros((noOfClasses,noOfClasses))\n","for i in range(noOfClasses):\n","    index = np.flatnonzero(yTest == i)\n","    for j in range(noOfClasses):\n","        index2 = np.flatnonzero(choice[index] == j)\n","        confusionMatrix[i,j] = len(index2)\n","print(confusionMatrix)\n","\n","print(\"\\n\")\n","scores = CNN.evaluate(XTest,YTest,batch_size=64)\n","print(\"Accuracy Test Set: %.2f%%\" % (scores[1]*100))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2KLJEIIv2U8H"},"source":["$\\color{red}{\\mbox{Aufgabe}}$: \n","\n","1.   Welche Test-Set Accuracy erreichen Sie?\n","2.   Wie viele Pferde werden irrtümlich als Flugzeuge erkannt?\n","3.   Visualisieren Sie (mithilfe der nachfolgenden Notebook-Zelle) das Filter-Mosaik für ein Auto-Bild und den 1. und 2. Faltungslayer. Interpretation?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VT2CpAURGbba"},"source":["## Output-Mosaic einiger Filter"]},{"cell_type":"code","metadata":{"id":"98VomO8KmSW-"},"source":["from keras import backend as K\n","\n","# Parameter:\n","#    imSingle: ein einzelnes Input-Bild, für das die Filter-Antworten gezeigt werden\n","#    outLayer: von welchem CNN-Layer 1,2,3, ... die Filter-Antworten gezeigt werden \n","def outputMoasic(imSingle, outLayer):\n","    pic = imSingle[np.newaxis,...]\n","    \n","    outputSingleLayer = K.function([CNN.layers[0].input],[CNN.layers[outLayer].output])\n","    picFilter = outputSingleLayer([pic])[0]\n","    \n","    gridy = 8\n","    gridx = 4 if outLayer < 4 else 8\n","    size = picFilter[0,:,:,0].shape[0] \n","    mosaic = np.zeros( (gridx*size,gridy*size))\n","    \n","    for l in range(0,picFilter.shape[3]):\n","        x = int(np.floor(l / gridy))\n","        y = l%gridy\n","        mosaic[x*size:(x+1)*size,y*size:(y+1)*size] = picFilter[0,:,:,l]\n","    plt.figure()\n","    plt.imshow(mosaic,cmap='binary')\n","    plt.show()\n","\n","#### Aufgabe \n","#??? outputMosaic(???,???)\n","#??? outputMosaic(???,???)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fyjqh5Um84F"},"source":["## Die falsche Accuracy\n","$\\color{red}{\\mbox{Programmieraufgabe}}$: Wenn man sich den Start der Arrays yTest und choice anschaut\n","\n","*   yTest =  [3 8 8 0 6 6 1 6 3 ...]\n","*   choice= [3 8 8 0 6 6 1 6 3 ...]\n","\n","so würde man meinen, dass `np.mean(yTest==choice)` auch die Testset-Accuracy berechnen würde. Finden Sie heraus, warum das falsch ist! Finden Sie eine Code Zeile, die  unter Verwendung von `yTest` und `choice` die richtige Accuracy berechnet:\n","\n","`??? accuracy = ... yTest ... choice ...`\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"IPz04oDcsFeD"},"source":["# ???"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4D3PQIi_CKLT"},"source":["$\\color{red}{\\mbox{Programmieraufgabe}}$: Bauen Sie den Parameter Lernrate in das CNN ein und testen Sie verschiedene Werte.\n","\n","Stellen Sie fest, wie viele Parameter das Netz in jedem Layer bzw. insgesamt hat.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ABzNLv9V06mK"},"source":["$\\color{red}{\\mbox{Programmieraufgabe}}$: Ändern Sie auf `loss='mse'` und dokumentieren Sie, was passiert.\n","\n"]},{"cell_type":"code","metadata":{"id":"WDjrWADfG9_S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"20eWKH6Zy6aQ"},"source":["## Vergleich mit MNIST-DNN\n","$\\color{red}{\\mbox{Programmieraufgabe}}$: Kopieren Sie die DNN-Architektur aus `mnist_sequential.ipynb` ein (vielleicht mit Aktivierung `softmax` im Output-Layer) und wenden Sie sie auf CIFAR-10 an. (ACHTUNG: Sie müssen die Input-Daten passend reshapen!)\n","\n","Welche Accuracy erreichen Sie mit DNN im Vergleich zum CNN?"]},{"cell_type":"code","metadata":{"id":"NfAkKpbx9-OY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WoF4rlsg94pm"},"source":["## Zum weiteren Experimentieren\n","$\\color{red}{\\mbox{Optionale Aufgabe}}$: Variieren Sie weitere Parameter (Batch Size, Epochen, Regularisierungskoeffizient) oder Elemente der Architektur (Aktivierungsfunktionen einzelner Layer, welche Layer Regularisierung haben, ..., andere CNN-Layer, ..., evtl. Einfügen eines Dropout-Layers, ...) und dokumentieren Sie, was passiert. "]}]}